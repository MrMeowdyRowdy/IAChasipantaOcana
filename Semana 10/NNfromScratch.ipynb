{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJ1__gbKbMof"
   },
   "source": [
    "**NEURAL NETWORKS FROM SCRATCH**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xv_MIR8EbSFC"
   },
   "source": [
    "Some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "D9myO0uLVw5Q"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '11'\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x);\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return 1-np.tanh(x)**2;\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.power(y_true-y_pred, 2));\n",
    "\n",
    "def mse_prime(y_true, y_pred):\n",
    "    return 2*(y_pred-y_true)/y_true.size;\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_prime(x):\n",
    "    return np.where(x > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AD3cq25vbWnL"
   },
   "source": [
    "Abstract class Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "shC2raflUZsF"
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    def forward_propagation(self, input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bl3z8vAFbgU7"
   },
   "source": [
    "Fully-connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "61YOw8K6UxWb"
   },
   "outputs": [],
   "source": [
    "class FCLayer(Layer):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.rand(input_size, output_size) - 0.5\n",
    "        self.bias = np.random.rand(1, output_size) - 0.5\n",
    "\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = np.dot(self.input, self.weights) + self.bias\n",
    "        return self.output\n",
    "\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        input_error = np.dot(output_error, self.weights.T)\n",
    "        weights_error = np.dot(self.input.T, output_error)\n",
    "        self.weights -= learning_rate * weights_error\n",
    "        self.bias -= learning_rate * output_error\n",
    "        return input_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Droput Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropoutLayer(Layer):\n",
    "    def __init__(self, p):\n",
    "        self.p = p\n",
    "        self.mask = None\n",
    "\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.mask = np.random.rand(*input_data.shape) > self.p\n",
    "        self.output = input_data * self.mask / (1 - self.p)\n",
    "        return self.output\n",
    "\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        return output_error * self.mask / (1 - self.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbuD-SqQbj8l"
   },
   "source": [
    "Activation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1lMLh140X6MT"
   },
   "outputs": [],
   "source": [
    "class ActivationLayer(Layer):\n",
    "    def __init__(self, activation, activation_prime):\n",
    "        self.activation = activation\n",
    "        self.activation_prime = activation_prime\n",
    "\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = self.activation(self.input)\n",
    "        return self.output\n",
    "\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        return self.activation_prime(self.input) * output_error\n",
    "    \n",
    "    def forward_propagation_dropout(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = self.activation(self.input)\n",
    "        return self.output\n",
    "\n",
    "    def backward_propagation_dropout(self, output_error, learning_rate):\n",
    "        return self.activation_prime(self.input) * output_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AX7yZmNobuKz"
   },
   "source": [
    "Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lJqPZmqaWT4d"
   },
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.loss = None\n",
    "        self.loss_prime = None\n",
    "\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def use(self, loss, loss_prime):\n",
    "        self.loss = loss\n",
    "        self.loss_prime = loss_prime\n",
    "\n",
    "    def predict(self, input_data):\n",
    "        samples = len(input_data)\n",
    "        result = []\n",
    "        for i in range(samples):\n",
    "            output = input_data[i]\n",
    "            for layer in self.layers:\n",
    "                output = layer.forward_propagation(output)\n",
    "            result.append(output)\n",
    "        return result\n",
    "\n",
    "    def fit(self, x_train, y_train, epochs, learning_rate):\n",
    "        samples = len(x_train)\n",
    "        for i in range(epochs):\n",
    "            err = 0\n",
    "            for j in range(samples):\n",
    "                output = x_train[j]\n",
    "                for layer in self.layers:\n",
    "                    output = layer.forward_propagation(output)\n",
    "                err += self.loss(y_train[j], output)\n",
    "                error = self.loss_prime(y_train[j], output)\n",
    "                for layer in reversed(self.layers):\n",
    "                    error = layer.backward_propagation(error, learning_rate)\n",
    "            err /= samples\n",
    "            print('epoch %d/%d   error=%f' % (i+1, epochs, err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0W0yuO39bzBJ"
   },
   "source": [
    "Solve the XOR problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oXfOveEZXTtC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/500   error=0.439734\n",
      "epoch 2/500   error=0.337554\n",
      "epoch 3/500   error=0.503549\n",
      "epoch 4/500   error=0.302155\n",
      "epoch 5/500   error=0.274435\n",
      "epoch 6/500   error=0.266073\n",
      "epoch 7/500   error=0.261782\n",
      "epoch 8/500   error=0.256543\n",
      "epoch 9/500   error=0.502442\n",
      "epoch 10/500   error=0.253332\n",
      "epoch 11/500   error=0.251993\n",
      "epoch 12/500   error=0.250028\n",
      "epoch 13/500   error=0.251212\n",
      "epoch 14/500   error=0.250602\n",
      "epoch 15/500   error=0.250329\n",
      "epoch 16/500   error=0.250172\n",
      "epoch 17/500   error=0.500067\n",
      "epoch 18/500   error=0.250059\n",
      "epoch 19/500   error=0.250039\n",
      "epoch 20/500   error=0.250019\n",
      "epoch 21/500   error=0.250009\n",
      "epoch 22/500   error=0.250005\n",
      "epoch 23/500   error=0.250000\n",
      "epoch 24/500   error=0.250003\n",
      "epoch 25/500   error=0.250001\n",
      "epoch 26/500   error=0.250001\n",
      "epoch 27/500   error=0.250000\n",
      "epoch 28/500   error=0.250000\n",
      "epoch 29/500   error=0.250000\n",
      "epoch 30/500   error=0.250000\n",
      "epoch 31/500   error=0.250000\n",
      "epoch 32/500   error=0.250000\n",
      "epoch 33/500   error=0.250000\n",
      "epoch 34/500   error=0.500000\n",
      "epoch 35/500   error=0.250000\n",
      "epoch 36/500   error=0.500000\n",
      "epoch 37/500   error=0.250000\n",
      "epoch 38/500   error=0.250000\n",
      "epoch 39/500   error=0.250000\n",
      "epoch 40/500   error=0.500000\n",
      "epoch 41/500   error=0.250000\n",
      "epoch 42/500   error=0.250000\n",
      "epoch 43/500   error=0.250000\n",
      "epoch 44/500   error=0.250000\n",
      "epoch 45/500   error=0.500000\n",
      "epoch 46/500   error=0.250000\n",
      "epoch 47/500   error=0.250000\n",
      "epoch 48/500   error=0.250000\n",
      "epoch 49/500   error=0.250000\n",
      "epoch 50/500   error=0.250000\n",
      "epoch 51/500   error=0.250000\n",
      "epoch 52/500   error=0.500000\n",
      "epoch 53/500   error=0.250000\n",
      "epoch 54/500   error=0.250000\n",
      "epoch 55/500   error=0.250000\n",
      "epoch 56/500   error=0.250000\n",
      "epoch 57/500   error=0.250000\n",
      "epoch 58/500   error=0.250000\n",
      "epoch 59/500   error=0.250000\n",
      "epoch 60/500   error=0.500000\n",
      "epoch 61/500   error=0.250000\n",
      "epoch 62/500   error=0.500000\n",
      "epoch 63/500   error=0.250000\n",
      "epoch 64/500   error=0.250000\n",
      "epoch 65/500   error=0.250000\n",
      "epoch 66/500   error=0.250000\n",
      "epoch 67/500   error=0.250000\n",
      "epoch 68/500   error=0.250000\n",
      "epoch 69/500   error=0.250000\n",
      "epoch 70/500   error=0.500000\n",
      "epoch 71/500   error=0.250000\n",
      "epoch 72/500   error=0.250000\n",
      "epoch 73/500   error=0.500000\n",
      "epoch 74/500   error=0.250000\n",
      "epoch 75/500   error=0.250000\n",
      "epoch 76/500   error=0.250000\n",
      "epoch 77/500   error=0.250000\n",
      "epoch 78/500   error=0.250000\n",
      "epoch 79/500   error=0.250000\n",
      "epoch 80/500   error=0.250000\n",
      "epoch 81/500   error=0.250000\n",
      "epoch 82/500   error=0.250000\n",
      "epoch 83/500   error=0.250000\n",
      "epoch 84/500   error=0.250000\n",
      "epoch 85/500   error=0.250000\n",
      "epoch 86/500   error=0.250000\n",
      "epoch 87/500   error=0.500000\n",
      "epoch 88/500   error=0.250000\n",
      "epoch 89/500   error=0.250000\n",
      "epoch 90/500   error=0.250000\n",
      "epoch 91/500   error=0.250000\n",
      "epoch 92/500   error=0.250000\n",
      "epoch 93/500   error=0.250000\n",
      "epoch 94/500   error=0.250000\n",
      "epoch 95/500   error=0.250000\n",
      "epoch 96/500   error=0.250000\n",
      "epoch 97/500   error=0.250000\n",
      "epoch 98/500   error=0.250000\n",
      "epoch 99/500   error=0.250000\n",
      "epoch 100/500   error=0.250000\n",
      "epoch 101/500   error=0.250000\n",
      "epoch 102/500   error=0.250000\n",
      "epoch 103/500   error=0.250000\n",
      "epoch 104/500   error=0.250000\n",
      "epoch 105/500   error=0.250000\n",
      "epoch 106/500   error=0.250000\n",
      "epoch 107/500   error=0.250000\n",
      "epoch 108/500   error=0.250000\n",
      "epoch 109/500   error=0.250000\n",
      "epoch 110/500   error=0.250000\n",
      "epoch 111/500   error=0.250000\n",
      "epoch 112/500   error=0.250000\n",
      "epoch 113/500   error=0.250000\n",
      "epoch 114/500   error=0.250000\n",
      "epoch 115/500   error=0.250000\n",
      "epoch 116/500   error=0.500000\n",
      "epoch 117/500   error=0.500000\n",
      "epoch 118/500   error=0.250000\n",
      "epoch 119/500   error=0.250000\n",
      "epoch 120/500   error=0.250000\n",
      "epoch 121/500   error=0.250000\n",
      "epoch 122/500   error=0.250000\n",
      "epoch 123/500   error=0.250000\n",
      "epoch 124/500   error=0.500000\n",
      "epoch 125/500   error=0.250000\n",
      "epoch 126/500   error=0.250000\n",
      "epoch 127/500   error=0.500000\n",
      "epoch 128/500   error=0.250000\n",
      "epoch 129/500   error=0.250000\n",
      "epoch 130/500   error=0.250000\n",
      "epoch 131/500   error=0.500000\n",
      "epoch 132/500   error=0.250000\n",
      "epoch 133/500   error=0.250000\n",
      "epoch 134/500   error=0.250000\n",
      "epoch 135/500   error=0.250000\n",
      "epoch 136/500   error=0.250000\n",
      "epoch 137/500   error=0.250000\n",
      "epoch 138/500   error=0.500000\n",
      "epoch 139/500   error=0.250000\n",
      "epoch 140/500   error=0.250000\n",
      "epoch 141/500   error=0.250000\n",
      "epoch 142/500   error=0.250000\n",
      "epoch 143/500   error=0.250000\n",
      "epoch 144/500   error=0.250000\n",
      "epoch 145/500   error=0.250000\n",
      "epoch 146/500   error=0.500000\n",
      "epoch 147/500   error=0.500000\n",
      "epoch 148/500   error=0.250000\n",
      "epoch 149/500   error=0.250000\n",
      "epoch 150/500   error=0.250000\n",
      "epoch 151/500   error=0.500000\n",
      "epoch 152/500   error=0.250000\n",
      "epoch 153/500   error=0.250000\n",
      "epoch 154/500   error=0.250000\n",
      "epoch 155/500   error=0.250000\n",
      "epoch 156/500   error=0.250000\n",
      "epoch 157/500   error=0.250000\n",
      "epoch 158/500   error=0.250000\n",
      "epoch 159/500   error=0.250000\n",
      "epoch 160/500   error=0.250000\n",
      "epoch 161/500   error=0.250000\n",
      "epoch 162/500   error=0.250000\n",
      "epoch 163/500   error=0.250000\n",
      "epoch 164/500   error=0.500000\n",
      "epoch 165/500   error=0.500000\n",
      "epoch 166/500   error=0.250000\n",
      "epoch 167/500   error=0.250000\n",
      "epoch 168/500   error=0.250000\n",
      "epoch 169/500   error=0.250000\n",
      "epoch 170/500   error=0.250000\n",
      "epoch 171/500   error=0.250000\n",
      "epoch 172/500   error=0.250000\n",
      "epoch 173/500   error=0.250000\n",
      "epoch 174/500   error=0.500000\n",
      "epoch 175/500   error=0.250000\n",
      "epoch 176/500   error=0.250000\n",
      "epoch 177/500   error=0.250000\n",
      "epoch 178/500   error=0.250000\n",
      "epoch 179/500   error=0.250000\n",
      "epoch 180/500   error=0.250000\n",
      "epoch 181/500   error=0.250000\n",
      "epoch 182/500   error=0.250000\n",
      "epoch 183/500   error=0.250000\n",
      "epoch 184/500   error=0.250000\n",
      "epoch 185/500   error=0.250000\n",
      "epoch 186/500   error=0.250000\n",
      "epoch 187/500   error=0.500000\n",
      "epoch 188/500   error=0.250000\n",
      "epoch 189/500   error=0.250000\n",
      "epoch 190/500   error=0.250000\n",
      "epoch 191/500   error=0.250000\n",
      "epoch 192/500   error=0.250000\n",
      "epoch 193/500   error=0.250000\n",
      "epoch 194/500   error=0.250000\n",
      "epoch 195/500   error=0.250000\n",
      "epoch 196/500   error=0.250000\n",
      "epoch 197/500   error=0.250000\n",
      "epoch 198/500   error=0.250000\n",
      "epoch 199/500   error=0.250000\n",
      "epoch 200/500   error=0.250000\n",
      "epoch 201/500   error=0.500000\n",
      "epoch 202/500   error=0.500000\n",
      "epoch 203/500   error=0.250000\n",
      "epoch 204/500   error=0.250000\n",
      "epoch 205/500   error=0.250000\n",
      "epoch 206/500   error=0.250000\n",
      "epoch 207/500   error=0.250000\n",
      "epoch 208/500   error=0.250000\n",
      "epoch 209/500   error=0.500000\n",
      "epoch 210/500   error=0.250000\n",
      "epoch 211/500   error=0.250000\n",
      "epoch 212/500   error=0.250000\n",
      "epoch 213/500   error=0.250000\n",
      "epoch 214/500   error=0.250000\n",
      "epoch 215/500   error=0.250000\n",
      "epoch 216/500   error=0.250000\n",
      "epoch 217/500   error=0.250000\n",
      "epoch 218/500   error=0.250000\n",
      "epoch 219/500   error=0.250000\n",
      "epoch 220/500   error=0.250000\n",
      "epoch 221/500   error=0.250000\n",
      "epoch 222/500   error=0.250000\n",
      "epoch 223/500   error=0.250000\n",
      "epoch 224/500   error=0.250000\n",
      "epoch 225/500   error=0.250000\n",
      "epoch 226/500   error=0.250000\n",
      "epoch 227/500   error=0.250000\n",
      "epoch 228/500   error=0.250000\n",
      "epoch 229/500   error=0.250000\n",
      "epoch 230/500   error=0.250000\n",
      "epoch 231/500   error=0.500000\n",
      "epoch 232/500   error=0.500000\n",
      "epoch 233/500   error=0.250000\n",
      "epoch 234/500   error=0.500000\n",
      "epoch 235/500   error=0.250000\n",
      "epoch 236/500   error=0.250000\n",
      "epoch 237/500   error=0.250000\n",
      "epoch 238/500   error=0.250000\n",
      "epoch 239/500   error=0.250000\n",
      "epoch 240/500   error=0.500000\n",
      "epoch 241/500   error=0.250000\n",
      "epoch 242/500   error=0.250000\n",
      "epoch 243/500   error=0.250000\n",
      "epoch 244/500   error=0.250000\n",
      "epoch 245/500   error=0.250000\n",
      "epoch 246/500   error=0.250000\n",
      "epoch 247/500   error=0.250000\n",
      "epoch 248/500   error=0.250000\n",
      "epoch 249/500   error=0.250000\n",
      "epoch 250/500   error=0.250000\n",
      "epoch 251/500   error=0.250000\n",
      "epoch 252/500   error=0.250000\n",
      "epoch 253/500   error=0.250000\n",
      "epoch 254/500   error=0.250000\n",
      "epoch 255/500   error=0.250000\n",
      "epoch 256/500   error=0.250000\n",
      "epoch 257/500   error=0.250000\n",
      "epoch 258/500   error=0.250000\n",
      "epoch 259/500   error=0.250000\n",
      "epoch 260/500   error=0.250000\n",
      "epoch 261/500   error=0.250000\n",
      "epoch 262/500   error=0.500000\n",
      "epoch 263/500   error=0.250000\n",
      "epoch 264/500   error=0.250000\n",
      "epoch 265/500   error=0.250000\n",
      "epoch 266/500   error=0.250000\n",
      "epoch 267/500   error=0.250000\n",
      "epoch 268/500   error=0.250000\n",
      "epoch 269/500   error=0.250000\n",
      "epoch 270/500   error=0.250000\n",
      "epoch 271/500   error=0.250000\n",
      "epoch 272/500   error=0.250000\n",
      "epoch 273/500   error=0.250000\n",
      "epoch 274/500   error=0.250000\n",
      "epoch 275/500   error=0.500000\n",
      "epoch 276/500   error=0.500000\n",
      "epoch 277/500   error=0.500000\n",
      "epoch 278/500   error=0.250000\n",
      "epoch 279/500   error=0.250000\n",
      "epoch 280/500   error=0.500000\n",
      "epoch 281/500   error=0.250000\n",
      "epoch 282/500   error=0.250000\n",
      "epoch 283/500   error=0.500000\n",
      "epoch 284/500   error=0.250000\n",
      "epoch 285/500   error=0.250000\n",
      "epoch 286/500   error=0.250000\n",
      "epoch 287/500   error=0.250000\n",
      "epoch 288/500   error=0.250000\n",
      "epoch 289/500   error=0.250000\n",
      "epoch 290/500   error=0.250000\n",
      "epoch 291/500   error=0.500000\n",
      "epoch 292/500   error=0.250000\n",
      "epoch 293/500   error=0.250000\n",
      "epoch 294/500   error=0.250000\n",
      "epoch 295/500   error=0.250000\n",
      "epoch 296/500   error=0.500000\n",
      "epoch 297/500   error=0.250000\n",
      "epoch 298/500   error=0.250000\n",
      "epoch 299/500   error=0.250000\n",
      "epoch 300/500   error=0.250000\n",
      "epoch 301/500   error=0.250000\n",
      "epoch 302/500   error=0.250000\n",
      "epoch 303/500   error=0.250000\n",
      "epoch 304/500   error=0.250000\n",
      "epoch 305/500   error=0.250000\n",
      "epoch 306/500   error=0.250000\n",
      "epoch 307/500   error=0.250000\n",
      "epoch 308/500   error=0.250000\n",
      "epoch 309/500   error=0.250000\n",
      "epoch 310/500   error=0.250000\n",
      "epoch 311/500   error=0.250000\n",
      "epoch 312/500   error=0.250000\n",
      "epoch 313/500   error=0.250000\n",
      "epoch 314/500   error=0.250000\n",
      "epoch 315/500   error=0.250000\n",
      "epoch 316/500   error=0.500000\n",
      "epoch 317/500   error=0.250000\n",
      "epoch 318/500   error=0.250000\n",
      "epoch 319/500   error=0.250000\n",
      "epoch 320/500   error=0.250000\n",
      "epoch 321/500   error=0.250000\n",
      "epoch 322/500   error=0.250000\n",
      "epoch 323/500   error=0.250000\n",
      "epoch 324/500   error=0.250000\n",
      "epoch 325/500   error=0.250000\n",
      "epoch 326/500   error=0.250000\n",
      "epoch 327/500   error=0.250000\n",
      "epoch 328/500   error=0.250000\n",
      "epoch 329/500   error=0.250000\n",
      "epoch 330/500   error=0.250000\n",
      "epoch 331/500   error=0.250000\n",
      "epoch 332/500   error=0.250000\n",
      "epoch 333/500   error=0.250000\n",
      "epoch 334/500   error=0.500000\n",
      "epoch 335/500   error=0.250000\n",
      "epoch 336/500   error=0.250000\n",
      "epoch 337/500   error=0.250000\n",
      "epoch 338/500   error=0.250000\n",
      "epoch 339/500   error=0.250000\n",
      "epoch 340/500   error=0.250000\n",
      "epoch 341/500   error=0.250000\n",
      "epoch 342/500   error=0.250000\n",
      "epoch 343/500   error=0.250000\n",
      "epoch 344/500   error=0.250000\n",
      "epoch 345/500   error=0.250000\n",
      "epoch 346/500   error=0.250000\n",
      "epoch 347/500   error=0.250000\n",
      "epoch 348/500   error=0.250000\n",
      "epoch 349/500   error=0.250000\n",
      "epoch 350/500   error=0.250000\n",
      "epoch 351/500   error=0.250000\n",
      "epoch 352/500   error=0.250000\n",
      "epoch 353/500   error=0.250000\n",
      "epoch 354/500   error=0.250000\n",
      "epoch 355/500   error=0.250000\n",
      "epoch 356/500   error=0.250000\n",
      "epoch 357/500   error=0.250000\n",
      "epoch 358/500   error=0.250000\n",
      "epoch 359/500   error=0.250000\n",
      "epoch 360/500   error=0.250000\n",
      "epoch 361/500   error=0.250000\n",
      "epoch 362/500   error=0.250000\n",
      "epoch 363/500   error=0.250000\n",
      "epoch 364/500   error=0.250000\n",
      "epoch 365/500   error=0.250000\n",
      "epoch 366/500   error=0.250000\n",
      "epoch 367/500   error=0.250000\n",
      "epoch 368/500   error=0.250000\n",
      "epoch 369/500   error=0.250000\n",
      "epoch 370/500   error=0.250000\n",
      "epoch 371/500   error=0.500000\n",
      "epoch 372/500   error=0.500000\n",
      "epoch 373/500   error=0.250000\n",
      "epoch 374/500   error=0.250000\n",
      "epoch 375/500   error=0.250000\n",
      "epoch 376/500   error=0.250000\n",
      "epoch 377/500   error=0.250000\n",
      "epoch 378/500   error=0.250000\n",
      "epoch 379/500   error=0.250000\n",
      "epoch 380/500   error=0.250000\n",
      "epoch 381/500   error=0.500000\n",
      "epoch 382/500   error=0.250000\n",
      "epoch 383/500   error=0.500000\n",
      "epoch 384/500   error=0.250000\n",
      "epoch 385/500   error=0.250000\n",
      "epoch 386/500   error=0.250000\n",
      "epoch 387/500   error=0.250000\n",
      "epoch 388/500   error=0.250000\n",
      "epoch 389/500   error=0.250000\n",
      "epoch 390/500   error=0.250000\n",
      "epoch 391/500   error=0.250000\n",
      "epoch 392/500   error=0.250000\n",
      "epoch 393/500   error=0.250000\n",
      "epoch 394/500   error=0.250000\n",
      "epoch 395/500   error=0.250000\n",
      "epoch 396/500   error=0.250000\n",
      "epoch 397/500   error=0.250000\n",
      "epoch 398/500   error=0.250000\n",
      "epoch 399/500   error=0.250000\n",
      "epoch 400/500   error=0.250000\n",
      "epoch 401/500   error=0.500000\n",
      "epoch 402/500   error=0.250000\n",
      "epoch 403/500   error=0.250000\n",
      "epoch 404/500   error=0.250000\n",
      "epoch 405/500   error=0.250000\n",
      "epoch 406/500   error=0.250000\n",
      "epoch 407/500   error=0.250000\n",
      "epoch 408/500   error=0.500000\n",
      "epoch 409/500   error=0.250000\n",
      "epoch 410/500   error=0.250000\n",
      "epoch 411/500   error=0.250000\n",
      "epoch 412/500   error=0.250000\n",
      "epoch 413/500   error=0.250000\n",
      "epoch 414/500   error=0.250000\n",
      "epoch 415/500   error=0.250000\n",
      "epoch 416/500   error=0.250000\n",
      "epoch 417/500   error=0.250000\n",
      "epoch 418/500   error=0.250000\n",
      "epoch 419/500   error=0.250000\n",
      "epoch 420/500   error=0.250000\n",
      "epoch 421/500   error=0.250000\n",
      "epoch 422/500   error=0.500000\n",
      "epoch 423/500   error=0.500000\n",
      "epoch 424/500   error=0.250000\n",
      "epoch 425/500   error=0.250000\n",
      "epoch 426/500   error=0.250000\n",
      "epoch 427/500   error=0.250000\n",
      "epoch 428/500   error=0.250000\n",
      "epoch 429/500   error=0.250000\n",
      "epoch 430/500   error=0.500000\n",
      "epoch 431/500   error=0.250000\n",
      "epoch 432/500   error=0.250000\n",
      "epoch 433/500   error=0.250000\n",
      "epoch 434/500   error=0.250000\n",
      "epoch 435/500   error=0.250000\n",
      "epoch 436/500   error=0.250000\n",
      "epoch 437/500   error=0.250000\n",
      "epoch 438/500   error=0.250000\n",
      "epoch 439/500   error=0.250000\n",
      "epoch 440/500   error=0.250000\n",
      "epoch 441/500   error=0.250000\n",
      "epoch 442/500   error=0.250000\n",
      "epoch 443/500   error=0.250000\n",
      "epoch 444/500   error=0.250000\n",
      "epoch 445/500   error=0.250000\n",
      "epoch 446/500   error=0.250000\n",
      "epoch 447/500   error=0.250000\n",
      "epoch 448/500   error=0.250000\n",
      "epoch 449/500   error=0.250000\n",
      "epoch 450/500   error=0.500000\n",
      "epoch 451/500   error=0.250000\n",
      "epoch 452/500   error=0.250000\n",
      "epoch 453/500   error=0.250000\n",
      "epoch 454/500   error=0.500000\n",
      "epoch 455/500   error=0.500000\n",
      "epoch 456/500   error=0.250000\n",
      "epoch 457/500   error=0.250000\n",
      "epoch 458/500   error=0.250000\n",
      "epoch 459/500   error=0.500000\n",
      "epoch 460/500   error=0.250000\n",
      "epoch 461/500   error=0.250000\n",
      "epoch 462/500   error=0.250000\n",
      "epoch 463/500   error=0.250000\n",
      "epoch 464/500   error=0.250000\n",
      "epoch 465/500   error=0.250000\n",
      "epoch 466/500   error=0.250000\n",
      "epoch 467/500   error=0.250000\n",
      "epoch 468/500   error=0.250000\n",
      "epoch 469/500   error=0.250000\n",
      "epoch 470/500   error=0.250000\n",
      "epoch 471/500   error=0.250000\n",
      "epoch 472/500   error=0.250000\n",
      "epoch 473/500   error=0.250000\n",
      "epoch 474/500   error=0.250000\n",
      "epoch 475/500   error=0.250000\n",
      "epoch 476/500   error=0.250000\n",
      "epoch 477/500   error=0.250000\n",
      "epoch 478/500   error=0.250000\n",
      "epoch 479/500   error=0.250000\n",
      "epoch 480/500   error=0.250000\n",
      "epoch 481/500   error=0.250000\n",
      "epoch 482/500   error=0.250000\n",
      "epoch 483/500   error=0.500000\n",
      "epoch 484/500   error=0.250000\n",
      "epoch 485/500   error=0.250000\n",
      "epoch 486/500   error=0.250000\n",
      "epoch 487/500   error=0.250000\n",
      "epoch 488/500   error=0.250000\n",
      "epoch 489/500   error=0.250000\n",
      "epoch 490/500   error=0.500000\n",
      "epoch 491/500   error=0.250000\n",
      "epoch 492/500   error=0.250000\n",
      "epoch 493/500   error=0.250000\n",
      "epoch 494/500   error=0.500000\n",
      "epoch 495/500   error=0.250000\n",
      "epoch 496/500   error=0.500000\n",
      "epoch 497/500   error=0.250000\n",
      "epoch 498/500   error=0.250000\n",
      "epoch 499/500   error=0.250000\n",
      "epoch 500/500   error=0.250000\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array([[[0,0]], [[0,1]], [[1,0]], [[1,1]]])\n",
    "y_train = np.array([[[0]], [[1]], [[1]], [[0]]])\n",
    "np.random.seed(10)\n",
    "net = Network()\n",
    "net.add(FCLayer(2, 10))\n",
    "net.add(ActivationLayer(relu, relu_prime))  # Use ReLU activation\n",
    "net.add(FCLayer(10, 1))\n",
    "net.add(ActivationLayer(relu, relu_prime))\n",
    "net.add(DropoutLayer(p=0.1))  # Add dropout layer\n",
    "net.use(mse, mse_prime)\n",
    "net.fit(x_train, y_train, epochs=500, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wOlyZneYb4US"
   },
   "source": [
    "Solve the MNIST problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x3qCOvvQZK0s"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0], 1, 28*28)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "y_train = to_categorical(y_train)\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, 28*28)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255\n",
    "y_test = to_categorical(y_test)\n",
    "np.random.seed(10)\n",
    "net = Network()\n",
    "net.add(FCLayer(28*28, 100))\n",
    "net.add(ActivationLayer(relu, relu_prime))  # Use ReLU activation\n",
    "net.add(FCLayer(100, 50))\n",
    "net.add(ActivationLayer(relu, relu_prime))  # Use ReLU activation\n",
    "net.add(FCLayer(50, 10))\n",
    "net.add(ActivationLayer(relu, relu_prime))\n",
    "net.add(DropoutLayer(p=0.1))  # Add dropout layer\n",
    "net.use(mse, mse_prime)\n",
    "net.fit(x_train, y_train, epochs=20, learning_rate=0.1)\n",
    "out = net.predict(x_test[0:10])\n",
    "print(\"\\n\")\n",
    "print(\"predicted values : \")\n",
    "print(out, end=\"\\n\")\n",
    "print(\"true values : \")\n",
    "print(y_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
