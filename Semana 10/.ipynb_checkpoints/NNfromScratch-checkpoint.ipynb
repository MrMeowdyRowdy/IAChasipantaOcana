{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJ1__gbKbMof"
   },
   "source": [
    "**NEURAL NETWORKS FROM SCRATCH**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xv_MIR8EbSFC"
   },
   "source": [
    "Some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "D9myO0uLVw5Q"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '11'\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x);\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return 1-np.tanh(x)**2;\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.power(y_true-y_pred, 2));\n",
    "\n",
    "def mse_prime(y_true, y_pred):\n",
    "    return 2*(y_pred-y_true)/y_true.size;\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_prime(x):\n",
    "    return np.where(x > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AD3cq25vbWnL"
   },
   "source": [
    "Abstract class Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "shC2raflUZsF"
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    def forward_propagation(self, input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bl3z8vAFbgU7"
   },
   "source": [
    "Fully-connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "61YOw8K6UxWb"
   },
   "outputs": [],
   "source": [
    "class FCLayer(Layer):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.rand(input_size, output_size) - 0.5\n",
    "        self.bias = np.random.rand(1, output_size) - 0.5\n",
    "\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = np.dot(self.input, self.weights) + self.bias\n",
    "        return self.output\n",
    "\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        input_error = np.dot(output_error, self.weights.T)\n",
    "        weights_error = np.dot(self.input.T, output_error)\n",
    "        self.weights -= learning_rate * weights_error\n",
    "        self.bias -= learning_rate * output_error\n",
    "        return input_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Droput Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropoutLayer(Layer):\n",
    "    def __init__(self, p):\n",
    "        self.p = p\n",
    "        self.mask = None\n",
    "\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.mask = np.random.rand(*input_data.shape) > self.p\n",
    "        self.output = input_data * self.mask / (1 - self.p)\n",
    "        return self.output\n",
    "\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        return output_error * self.mask / (1 - self.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbuD-SqQbj8l"
   },
   "source": [
    "Activation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "1lMLh140X6MT"
   },
   "outputs": [],
   "source": [
    "class ActivationLayer(Layer):\n",
    "    def __init__(self, activation, activation_prime):\n",
    "        self.activation = activation\n",
    "        self.activation_prime = activation_prime\n",
    "\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = self.activation(self.input)\n",
    "        return self.output\n",
    "\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        return self.activation_prime(self.input) * output_error\n",
    "    \n",
    "    def forward_propagation_dropout(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = self.activation(self.input)\n",
    "        return self.output\n",
    "\n",
    "    def backward_propagation_dropout(self, output_error, learning_rate):\n",
    "        return self.activation_prime(self.input) * output_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AX7yZmNobuKz"
   },
   "source": [
    "Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "lJqPZmqaWT4d"
   },
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.loss = None\n",
    "        self.loss_prime = None\n",
    "\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def use(self, loss, loss_prime):\n",
    "        self.loss = loss\n",
    "        self.loss_prime = loss_prime\n",
    "\n",
    "    def predict(self, input_data):\n",
    "        samples = len(input_data)\n",
    "        result = []\n",
    "        for i in range(samples):\n",
    "            output = input_data[i]\n",
    "            for layer in self.layers:\n",
    "                output = layer.forward_propagation(output)\n",
    "            result.append(output)\n",
    "        return result\n",
    "\n",
    "    def fit(self, x_train, y_train, epochs, learning_rate):\n",
    "        samples = len(x_train)\n",
    "        for i in range(epochs):\n",
    "            err = 0\n",
    "            for j in range(samples):\n",
    "                output = x_train[j]\n",
    "                for layer in self.layers:\n",
    "                    output = layer.forward_propagation(output)\n",
    "                err += self.loss(y_train[j], output)\n",
    "                error = self.loss_prime(y_train[j], output)\n",
    "                for layer in reversed(self.layers):\n",
    "                    error = layer.backward_propagation(error, learning_rate)\n",
    "            err /= samples\n",
    "            print('epoch %d/%d   error=%f' % (i+1, epochs, err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0W0yuO39bzBJ"
   },
   "source": [
    "Solve the XOR problem ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "oXfOveEZXTtC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/500   error=0.408052\n",
      "epoch 2/500   error=0.370493\n",
      "epoch 3/500   error=0.317765\n",
      "epoch 4/500   error=0.354062\n",
      "epoch 5/500   error=0.208899\n",
      "epoch 6/500   error=0.330154\n",
      "epoch 7/500   error=0.325149\n",
      "epoch 8/500   error=0.271991\n",
      "epoch 9/500   error=0.260267\n",
      "epoch 10/500   error=0.270214\n",
      "epoch 11/500   error=0.253238\n",
      "epoch 12/500   error=0.386419\n",
      "epoch 13/500   error=0.297254\n",
      "epoch 14/500   error=0.269202\n",
      "epoch 15/500   error=0.318728\n",
      "epoch 16/500   error=0.257841\n",
      "epoch 17/500   error=0.266896\n",
      "epoch 18/500   error=0.254251\n",
      "epoch 19/500   error=0.250129\n",
      "epoch 20/500   error=0.250991\n",
      "epoch 21/500   error=0.259996\n",
      "epoch 22/500   error=0.250001\n",
      "epoch 23/500   error=0.250000\n",
      "epoch 24/500   error=0.255236\n",
      "epoch 25/500   error=0.250111\n",
      "epoch 26/500   error=0.250000\n",
      "epoch 27/500   error=0.253675\n",
      "epoch 28/500   error=0.334622\n",
      "epoch 29/500   error=0.250145\n",
      "epoch 30/500   error=0.269934\n",
      "epoch 31/500   error=0.250735\n",
      "epoch 32/500   error=0.252057\n",
      "epoch 33/500   error=0.270597\n",
      "epoch 34/500   error=0.257834\n",
      "epoch 35/500   error=0.250002\n",
      "epoch 36/500   error=0.250000\n",
      "epoch 37/500   error=0.267942\n",
      "epoch 38/500   error=0.259846\n",
      "epoch 39/500   error=0.250014\n",
      "epoch 40/500   error=0.264644\n",
      "epoch 41/500   error=0.250009\n",
      "epoch 42/500   error=0.250000\n",
      "epoch 43/500   error=0.251350\n",
      "epoch 44/500   error=0.250037\n",
      "epoch 45/500   error=0.250019\n",
      "epoch 46/500   error=0.252617\n",
      "epoch 47/500   error=0.260696\n",
      "epoch 48/500   error=0.250489\n",
      "epoch 49/500   error=0.259671\n",
      "epoch 50/500   error=0.271433\n",
      "epoch 51/500   error=0.260269\n",
      "epoch 52/500   error=0.250847\n",
      "epoch 53/500   error=0.104962\n",
      "epoch 54/500   error=0.269305\n",
      "epoch 55/500   error=0.250750\n",
      "epoch 56/500   error=0.277459\n",
      "epoch 57/500   error=0.250000\n",
      "epoch 58/500   error=0.250000\n",
      "epoch 59/500   error=0.250000\n",
      "epoch 60/500   error=0.255341\n",
      "epoch 61/500   error=0.251685\n",
      "epoch 62/500   error=0.251376\n",
      "epoch 63/500   error=0.250495\n",
      "epoch 64/500   error=0.259761\n",
      "epoch 65/500   error=0.280143\n",
      "epoch 66/500   error=0.267257\n",
      "epoch 67/500   error=0.266690\n",
      "epoch 68/500   error=0.286876\n",
      "epoch 69/500   error=0.263055\n",
      "epoch 70/500   error=0.250062\n",
      "epoch 71/500   error=0.245733\n",
      "epoch 72/500   error=0.257021\n",
      "epoch 73/500   error=0.451443\n",
      "epoch 74/500   error=0.261793\n",
      "epoch 75/500   error=0.265124\n",
      "epoch 76/500   error=0.286768\n",
      "epoch 77/500   error=0.297046\n",
      "epoch 78/500   error=0.250743\n",
      "epoch 79/500   error=0.250002\n",
      "epoch 80/500   error=0.278511\n",
      "epoch 81/500   error=0.257152\n",
      "epoch 82/500   error=0.273619\n",
      "epoch 83/500   error=0.259053\n",
      "epoch 84/500   error=0.250374\n",
      "epoch 85/500   error=0.250025\n",
      "epoch 86/500   error=0.278146\n",
      "epoch 87/500   error=0.252647\n",
      "epoch 88/500   error=0.258037\n",
      "epoch 89/500   error=0.250414\n",
      "epoch 90/500   error=0.250030\n",
      "epoch 91/500   error=0.250002\n",
      "epoch 92/500   error=0.333593\n",
      "epoch 93/500   error=0.250530\n",
      "epoch 94/500   error=0.165749\n",
      "epoch 95/500   error=0.324499\n",
      "epoch 96/500   error=0.255895\n",
      "epoch 97/500   error=0.250276\n",
      "epoch 98/500   error=0.250033\n",
      "epoch 99/500   error=0.283793\n",
      "epoch 100/500   error=0.134423\n",
      "epoch 101/500   error=0.256273\n",
      "epoch 102/500   error=0.250569\n",
      "epoch 103/500   error=0.250332\n",
      "epoch 104/500   error=0.250000\n",
      "epoch 105/500   error=0.250027\n",
      "epoch 106/500   error=0.311348\n",
      "epoch 107/500   error=0.285146\n",
      "epoch 108/500   error=0.250012\n",
      "epoch 109/500   error=0.250001\n",
      "epoch 110/500   error=0.281707\n",
      "epoch 111/500   error=0.025006\n",
      "epoch 112/500   error=0.308830\n",
      "epoch 113/500   error=0.291814\n",
      "epoch 114/500   error=0.256079\n",
      "epoch 115/500   error=0.250373\n",
      "epoch 116/500   error=0.267452\n",
      "epoch 117/500   error=0.276100\n",
      "epoch 118/500   error=0.252442\n",
      "epoch 119/500   error=0.259564\n",
      "epoch 120/500   error=0.250000\n",
      "epoch 121/500   error=0.255822\n",
      "epoch 122/500   error=0.315956\n",
      "epoch 123/500   error=0.267049\n",
      "epoch 124/500   error=0.250182\n",
      "epoch 125/500   error=0.201488\n",
      "epoch 126/500   error=0.263979\n",
      "epoch 127/500   error=0.250516\n",
      "epoch 128/500   error=0.250032\n",
      "epoch 129/500   error=0.039345\n",
      "epoch 130/500   error=0.268822\n",
      "epoch 131/500   error=0.020291\n",
      "epoch 132/500   error=0.250508\n",
      "epoch 133/500   error=0.268795\n",
      "epoch 134/500   error=0.011040\n",
      "epoch 135/500   error=0.312313\n",
      "epoch 136/500   error=0.250004\n",
      "epoch 137/500   error=0.250000\n",
      "epoch 138/500   error=0.268985\n",
      "epoch 139/500   error=0.251105\n",
      "epoch 140/500   error=0.005733\n",
      "epoch 141/500   error=0.286360\n",
      "epoch 142/500   error=0.250092\n",
      "epoch 143/500   error=0.284273\n",
      "epoch 144/500   error=0.250104\n",
      "epoch 145/500   error=0.250006\n",
      "epoch 146/500   error=0.251514\n",
      "epoch 147/500   error=0.361981\n",
      "epoch 148/500   error=0.043905\n",
      "epoch 149/500   error=0.266580\n",
      "epoch 150/500   error=0.251316\n",
      "epoch 151/500   error=0.250065\n",
      "epoch 152/500   error=0.250003\n",
      "epoch 153/500   error=0.271816\n",
      "epoch 154/500   error=0.288329\n",
      "epoch 155/500   error=0.267589\n",
      "epoch 156/500   error=0.259072\n",
      "epoch 157/500   error=0.250103\n",
      "epoch 158/500   error=0.250108\n",
      "epoch 159/500   error=0.075427\n",
      "epoch 160/500   error=0.265088\n",
      "epoch 161/500   error=0.250073\n",
      "epoch 162/500   error=0.250650\n",
      "epoch 163/500   error=0.005151\n",
      "epoch 164/500   error=0.250717\n",
      "epoch 165/500   error=0.338748\n",
      "epoch 166/500   error=0.250054\n",
      "epoch 167/500   error=0.250127\n",
      "epoch 168/500   error=0.250068\n",
      "epoch 169/500   error=0.316263\n",
      "epoch 170/500   error=0.258514\n",
      "epoch 171/500   error=0.263740\n",
      "epoch 172/500   error=0.250004\n",
      "epoch 173/500   error=0.250000\n",
      "epoch 174/500   error=0.250011\n",
      "epoch 175/500   error=0.250007\n",
      "epoch 176/500   error=0.250008\n",
      "epoch 177/500   error=0.138932\n",
      "epoch 178/500   error=0.250171\n",
      "epoch 179/500   error=0.251211\n",
      "epoch 180/500   error=0.250081\n",
      "epoch 181/500   error=0.250006\n",
      "epoch 182/500   error=0.250000\n",
      "epoch 183/500   error=0.309303\n",
      "epoch 184/500   error=0.250116\n",
      "epoch 185/500   error=0.000775\n",
      "epoch 186/500   error=0.270369\n",
      "epoch 187/500   error=0.250047\n",
      "epoch 188/500   error=0.257310\n",
      "epoch 189/500   error=0.250568\n",
      "epoch 190/500   error=0.250027\n",
      "epoch 191/500   error=0.250001\n",
      "epoch 192/500   error=0.250404\n",
      "epoch 193/500   error=0.250233\n",
      "epoch 194/500   error=0.250009\n",
      "epoch 195/500   error=0.297357\n",
      "epoch 196/500   error=0.261219\n",
      "epoch 197/500   error=0.266766\n",
      "epoch 198/500   error=0.260890\n",
      "epoch 199/500   error=0.004564\n",
      "epoch 200/500   error=0.250001\n",
      "epoch 201/500   error=0.301701\n",
      "epoch 202/500   error=0.250257\n",
      "epoch 203/500   error=0.250000\n",
      "epoch 204/500   error=0.261681\n",
      "epoch 205/500   error=0.250153\n",
      "epoch 206/500   error=0.250130\n",
      "epoch 207/500   error=0.393781\n",
      "epoch 208/500   error=0.012593\n",
      "epoch 209/500   error=0.250670\n",
      "epoch 210/500   error=0.286276\n",
      "epoch 211/500   error=0.309150\n",
      "epoch 212/500   error=0.250468\n",
      "epoch 213/500   error=0.261198\n",
      "epoch 214/500   error=0.274880\n",
      "epoch 215/500   error=0.052022\n",
      "epoch 216/500   error=0.001003\n",
      "epoch 217/500   error=0.391057\n",
      "epoch 218/500   error=0.152674\n",
      "epoch 219/500   error=0.098999\n",
      "epoch 220/500   error=0.024550\n",
      "epoch 221/500   error=0.005863\n",
      "epoch 222/500   error=0.219268\n",
      "epoch 223/500   error=0.105588\n",
      "epoch 224/500   error=0.019785\n",
      "epoch 225/500   error=0.061371\n",
      "epoch 226/500   error=0.017994\n",
      "epoch 227/500   error=0.029345\n",
      "epoch 228/500   error=0.002373\n",
      "epoch 229/500   error=0.058616\n",
      "epoch 230/500   error=0.083412\n",
      "epoch 231/500   error=0.005023\n",
      "epoch 232/500   error=0.002875\n",
      "epoch 233/500   error=0.000499\n",
      "epoch 234/500   error=0.206582\n",
      "epoch 235/500   error=0.040007\n",
      "epoch 236/500   error=0.002020\n",
      "epoch 237/500   error=0.142838\n",
      "epoch 238/500   error=0.030990\n",
      "epoch 239/500   error=0.007187\n",
      "epoch 240/500   error=0.003802\n",
      "epoch 241/500   error=0.016651\n",
      "epoch 242/500   error=0.059990\n",
      "epoch 243/500   error=0.041158\n",
      "epoch 244/500   error=0.019890\n",
      "epoch 245/500   error=0.081004\n",
      "epoch 246/500   error=0.022649\n",
      "epoch 247/500   error=0.005581\n",
      "epoch 248/500   error=0.002244\n",
      "epoch 249/500   error=0.005534\n",
      "epoch 250/500   error=0.005643\n",
      "epoch 251/500   error=0.091093\n",
      "epoch 252/500   error=0.050859\n",
      "epoch 253/500   error=0.075357\n",
      "epoch 254/500   error=0.011147\n",
      "epoch 255/500   error=0.041511\n",
      "epoch 256/500   error=0.000879\n",
      "epoch 257/500   error=0.000258\n",
      "epoch 258/500   error=0.039327\n",
      "epoch 259/500   error=0.014342\n",
      "epoch 260/500   error=0.000407\n",
      "epoch 261/500   error=0.000081\n",
      "epoch 262/500   error=0.033617\n",
      "epoch 263/500   error=0.011628\n",
      "epoch 264/500   error=0.004202\n",
      "epoch 265/500   error=0.001846\n",
      "epoch 266/500   error=0.000017\n",
      "epoch 267/500   error=0.000335\n",
      "epoch 268/500   error=0.061672\n",
      "epoch 269/500   error=0.113254\n",
      "epoch 270/500   error=0.104675\n",
      "epoch 271/500   error=0.194374\n",
      "epoch 272/500   error=0.178739\n",
      "epoch 273/500   error=0.080975\n",
      "epoch 274/500   error=0.015002\n",
      "epoch 275/500   error=0.023926\n",
      "epoch 276/500   error=0.007699\n",
      "epoch 277/500   error=0.007044\n",
      "epoch 278/500   error=0.057535\n",
      "epoch 279/500   error=0.025194\n",
      "epoch 280/500   error=0.007941\n",
      "epoch 281/500   error=0.128929\n",
      "epoch 282/500   error=0.034275\n",
      "epoch 283/500   error=0.067637\n",
      "epoch 284/500   error=0.017124\n",
      "epoch 285/500   error=0.002716\n",
      "epoch 286/500   error=0.001850\n",
      "epoch 287/500   error=0.000951\n",
      "epoch 288/500   error=0.006015\n",
      "epoch 289/500   error=0.006514\n",
      "epoch 290/500   error=0.003301\n",
      "epoch 291/500   error=0.007702\n",
      "epoch 292/500   error=0.004518\n",
      "epoch 293/500   error=0.082768\n",
      "epoch 294/500   error=0.036703\n",
      "epoch 295/500   error=0.101159\n",
      "epoch 296/500   error=0.021940\n",
      "epoch 297/500   error=0.000158\n",
      "epoch 298/500   error=0.000094\n",
      "epoch 299/500   error=0.000066\n",
      "epoch 300/500   error=0.000047\n",
      "epoch 301/500   error=0.000034\n",
      "epoch 302/500   error=0.003071\n",
      "epoch 303/500   error=0.000155\n",
      "epoch 304/500   error=0.001137\n",
      "epoch 305/500   error=0.002045\n",
      "epoch 306/500   error=0.088667\n",
      "epoch 307/500   error=0.079978\n",
      "epoch 308/500   error=0.009718\n",
      "epoch 309/500   error=0.000865\n",
      "epoch 310/500   error=0.003574\n",
      "epoch 311/500   error=0.000338\n",
      "epoch 312/500   error=0.002196\n",
      "epoch 313/500   error=0.000220\n",
      "epoch 314/500   error=0.000274\n",
      "epoch 315/500   error=0.000166\n",
      "epoch 316/500   error=0.000014\n",
      "epoch 317/500   error=0.000090\n",
      "epoch 318/500   error=0.000063\n",
      "epoch 319/500   error=0.000205\n",
      "epoch 320/500   error=0.109793\n",
      "epoch 321/500   error=0.033174\n",
      "epoch 322/500   error=0.104831\n",
      "epoch 323/500   error=0.008199\n",
      "epoch 324/500   error=0.056562\n",
      "epoch 325/500   error=0.030449\n",
      "epoch 326/500   error=0.001187\n",
      "epoch 327/500   error=0.002745\n",
      "epoch 328/500   error=0.074600\n",
      "epoch 329/500   error=0.021581\n",
      "epoch 330/500   error=0.001242\n",
      "epoch 331/500   error=0.000308\n",
      "epoch 332/500   error=0.000177\n",
      "epoch 333/500   error=0.000078\n",
      "epoch 334/500   error=0.079529\n",
      "epoch 335/500   error=0.014613\n",
      "epoch 336/500   error=0.049495\n",
      "epoch 337/500   error=0.073676\n",
      "epoch 338/500   error=0.036044\n",
      "epoch 339/500   error=0.086169\n",
      "epoch 340/500   error=0.044005\n",
      "epoch 341/500   error=0.098324\n",
      "epoch 342/500   error=0.009012\n",
      "epoch 343/500   error=0.002370\n",
      "epoch 344/500   error=0.061368\n",
      "epoch 345/500   error=0.017233\n",
      "epoch 346/500   error=0.013273\n",
      "epoch 347/500   error=0.085228\n",
      "epoch 348/500   error=0.036835\n",
      "epoch 349/500   error=0.000887\n",
      "epoch 350/500   error=0.063002\n",
      "epoch 351/500   error=0.014038\n",
      "epoch 352/500   error=0.001439\n",
      "epoch 353/500   error=0.001055\n",
      "epoch 354/500   error=0.000794\n",
      "epoch 355/500   error=0.001733\n",
      "epoch 356/500   error=0.000486\n",
      "epoch 357/500   error=0.000703\n",
      "epoch 358/500   error=0.000329\n",
      "epoch 359/500   error=0.000811\n",
      "epoch 360/500   error=0.000372\n",
      "epoch 361/500   error=0.077470\n",
      "epoch 362/500   error=0.064250\n",
      "epoch 363/500   error=0.008860\n",
      "epoch 364/500   error=0.001655\n",
      "epoch 365/500   error=0.001527\n",
      "epoch 366/500   error=0.106909\n",
      "epoch 367/500   error=0.028661\n",
      "epoch 368/500   error=0.002411\n",
      "epoch 369/500   error=0.002063\n",
      "epoch 370/500   error=0.000609\n",
      "epoch 371/500   error=0.052211\n",
      "epoch 372/500   error=0.025364\n",
      "epoch 373/500   error=0.000633\n",
      "epoch 374/500   error=0.038103\n",
      "epoch 375/500   error=0.059203\n",
      "epoch 376/500   error=0.100129\n",
      "epoch 377/500   error=0.009051\n",
      "epoch 378/500   error=0.007896\n",
      "epoch 379/500   error=0.137282\n",
      "epoch 380/500   error=0.047717\n",
      "epoch 381/500   error=0.005544\n",
      "epoch 382/500   error=0.001736\n",
      "epoch 383/500   error=0.001275\n",
      "epoch 384/500   error=0.000786\n",
      "epoch 385/500   error=0.040543\n",
      "epoch 386/500   error=0.094669\n",
      "epoch 387/500   error=0.049380\n",
      "epoch 388/500   error=0.040440\n",
      "epoch 389/500   error=0.008833\n",
      "epoch 390/500   error=0.004985\n",
      "epoch 391/500   error=0.000396\n",
      "epoch 392/500   error=0.000376\n",
      "epoch 393/500   error=0.000609\n",
      "epoch 394/500   error=0.002880\n",
      "epoch 395/500   error=0.000797\n",
      "epoch 396/500   error=0.000186\n",
      "epoch 397/500   error=0.000230\n",
      "epoch 398/500   error=0.060750\n",
      "epoch 399/500   error=0.015636\n",
      "epoch 400/500   error=0.000094\n",
      "epoch 401/500   error=0.038876\n",
      "epoch 402/500   error=0.016750\n",
      "epoch 403/500   error=0.000027\n",
      "epoch 404/500   error=0.087873\n",
      "epoch 405/500   error=0.044437\n",
      "epoch 406/500   error=0.132014\n",
      "epoch 407/500   error=0.075900\n",
      "epoch 408/500   error=0.017161\n",
      "epoch 409/500   error=0.069512\n",
      "epoch 410/500   error=0.029808\n",
      "epoch 411/500   error=0.014880\n",
      "epoch 412/500   error=0.042294\n",
      "epoch 413/500   error=0.097685\n",
      "epoch 414/500   error=0.015039\n",
      "epoch 415/500   error=0.002640\n",
      "epoch 416/500   error=0.001502\n",
      "epoch 417/500   error=0.038866\n",
      "epoch 418/500   error=0.058445\n",
      "epoch 419/500   error=0.257101\n",
      "epoch 420/500   error=0.011647\n",
      "epoch 421/500   error=0.009700\n",
      "epoch 422/500   error=0.129632\n",
      "epoch 423/500   error=0.026846\n",
      "epoch 424/500   error=0.001917\n",
      "epoch 425/500   error=0.001769\n",
      "epoch 426/500   error=0.002306\n",
      "epoch 427/500   error=0.072851\n",
      "epoch 428/500   error=0.086567\n",
      "epoch 429/500   error=0.048779\n",
      "epoch 430/500   error=0.038635\n",
      "epoch 431/500   error=0.003894\n",
      "epoch 432/500   error=0.002214\n",
      "epoch 433/500   error=0.001892\n",
      "epoch 434/500   error=0.001938\n",
      "epoch 435/500   error=0.047577\n",
      "epoch 436/500   error=0.020038\n",
      "epoch 437/500   error=0.001080\n",
      "epoch 438/500   error=0.056370\n",
      "epoch 439/500   error=0.014052\n",
      "epoch 440/500   error=0.000859\n",
      "epoch 441/500   error=0.127213\n",
      "epoch 442/500   error=0.018927\n",
      "epoch 443/500   error=0.057404\n",
      "epoch 444/500   error=0.015360\n",
      "epoch 445/500   error=0.000530\n",
      "epoch 446/500   error=0.000351\n",
      "epoch 447/500   error=0.000256\n",
      "epoch 448/500   error=0.079245\n",
      "epoch 449/500   error=0.021721\n",
      "epoch 450/500   error=0.002452\n",
      "epoch 451/500   error=0.000907\n",
      "epoch 452/500   error=0.041073\n",
      "epoch 453/500   error=0.012165\n",
      "epoch 454/500   error=0.000457\n",
      "epoch 455/500   error=0.000156\n",
      "epoch 456/500   error=0.055536\n",
      "epoch 457/500   error=0.037753\n",
      "epoch 458/500   error=0.045769\n",
      "epoch 459/500   error=0.001949\n",
      "epoch 460/500   error=0.000340\n",
      "epoch 461/500   error=0.000201\n",
      "epoch 462/500   error=0.009379\n",
      "epoch 463/500   error=0.101584\n",
      "epoch 464/500   error=0.016401\n",
      "epoch 465/500   error=0.080998\n",
      "epoch 466/500   error=0.024409\n",
      "epoch 467/500   error=0.001428\n",
      "epoch 468/500   error=0.046663\n",
      "epoch 469/500   error=0.015983\n",
      "epoch 470/500   error=0.068113\n",
      "epoch 471/500   error=0.069453\n",
      "epoch 472/500   error=0.032150\n",
      "epoch 473/500   error=0.001673\n",
      "epoch 474/500   error=0.000933\n",
      "epoch 475/500   error=0.000664\n",
      "epoch 476/500   error=0.000488\n",
      "epoch 477/500   error=0.038864\n",
      "epoch 478/500   error=0.004390\n",
      "epoch 479/500   error=0.018096\n",
      "epoch 480/500   error=0.001211\n",
      "epoch 481/500   error=0.000018\n",
      "epoch 482/500   error=0.000012\n",
      "epoch 483/500   error=0.008215\n",
      "epoch 484/500   error=0.182189\n",
      "epoch 485/500   error=0.021873\n",
      "epoch 486/500   error=0.053059\n",
      "epoch 487/500   error=0.019954\n",
      "epoch 488/500   error=0.000124\n",
      "epoch 489/500   error=0.000040\n",
      "epoch 490/500   error=0.001543\n",
      "epoch 491/500   error=0.000785\n",
      "epoch 492/500   error=0.000171\n",
      "epoch 493/500   error=0.071720\n",
      "epoch 494/500   error=0.030743\n",
      "epoch 495/500   error=0.000437\n",
      "epoch 496/500   error=0.001078\n",
      "epoch 497/500   error=0.194756\n",
      "epoch 498/500   error=0.077550\n",
      "epoch 499/500   error=0.043187\n",
      "epoch 500/500   error=0.082410\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array([[[0,0]], [[0,1]], [[1,0]], [[1,1]]])\n",
    "y_train = np.array([[[0]], [[1]], [[1]], [[0]]])\n",
    "np.random.seed(10)\n",
    "net = Network()\n",
    "net.add(FCLayer(2, 10))\n",
    "net.add(ActivationLayer(relu, relu_prime))  # Use ReLU activation\n",
    "net.add(DropoutLayer(p=0.1))  # Add dropout layer\n",
    "net.add(FCLayer(10, 1))\n",
    "net.add(ActivationLayer(relu, relu_prime))\n",
    "net.use(mse, mse_prime)\n",
    "net.fit(x_train, y_train, epochs=500, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wOlyZneYb4US"
   },
   "source": [
    "Solve the MNIST problem ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "x3qCOvvQZK0s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/20   error=3947886691824435468380254489894103931519315739786260544691370348873126208501448704.000000\n",
      "epoch 2/20   error=0.100000\n",
      "epoch 3/20   error=0.100000\n",
      "epoch 4/20   error=0.100000\n",
      "epoch 5/20   error=0.100000\n",
      "epoch 6/20   error=0.100000\n",
      "epoch 7/20   error=0.100000\n",
      "epoch 8/20   error=0.100000\n",
      "epoch 9/20   error=0.100000\n",
      "epoch 10/20   error=0.100000\n",
      "epoch 11/20   error=0.100000\n",
      "epoch 12/20   error=0.100000\n",
      "epoch 13/20   error=0.100000\n",
      "epoch 14/20   error=0.100000\n",
      "epoch 15/20   error=0.100000\n",
      "epoch 16/20   error=0.100000\n",
      "epoch 17/20   error=0.100000\n",
      "epoch 18/20   error=0.100000\n",
      "epoch 19/20   error=0.100000\n",
      "epoch 20/20   error=0.100000\n",
      "\n",
      "\n",
      "predicted values : \n",
      "[array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "true values : \n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0], 1, 28*28)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "y_train = to_categorical(y_train)\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, 28*28)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255\n",
    "y_test = to_categorical(y_test)\n",
    "np.random.seed(10)\n",
    "net = Network()\n",
    "net.add(FCLayer(28*28, 100))\n",
    "net.add(ActivationLayer(relu, relu_prime))  # Use ReLU activation\n",
    "net.add(FCLayer(100, 50))\n",
    "net.add(ActivationLayer(relu, relu_prime))\n",
    "net.add(DropoutLayer(p=0.1))  # Add dropout layer# Use ReLU activation\n",
    "net.add(FCLayer(50, 10))\n",
    "net.add(ActivationLayer(relu, relu_prime))\n",
    "\n",
    "net.use(mse, mse_prime)\n",
    "net.fit(x_train, y_train, epochs=20, learning_rate=0.1)\n",
    "out = net.predict(x_test[0:10])\n",
    "print(\"\\n\")\n",
    "print(\"predicted values : \")\n",
    "print(out, end=\"\\n\")\n",
    "print(\"true values : \")\n",
    "print(y_test[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([[[0,0]], [[0,1]], [[1,0]], [[1,1]]])\n",
    "y_train = np.array([[[0]], [[1]], [[1]], [[0]]])\n",
    "np.random.seed(10)\n",
    "net = Network()\n",
    "net.add(FCLayer(2, 10))\n",
    "net.add(ActivationLayer(tanh, tanh_prime))\n",
    "net.add(FCLayer(3, 1))\n",
    "net.add(ActivationLayer(tanh, tanh_prime))\n",
    "net.use(mse, mse_prime)\n",
    "net.fit(x_train, y_train, epochs=500, learning_rate=0.1)\n",
    "out = net.predict(x_train)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular MNisT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/20   error=0.042247\n",
      "epoch 2/20   error=0.021373\n",
      "epoch 3/20   error=0.017366\n",
      "epoch 4/20   error=0.015063\n",
      "epoch 5/20   error=0.013448\n",
      "epoch 6/20   error=0.012274\n",
      "epoch 7/20   error=0.011323\n",
      "epoch 8/20   error=0.010582\n",
      "epoch 9/20   error=0.009878\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0], 1, 28*28)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "y_train = to_categorical(y_train)\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, 28*28)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255\n",
    "y_test = to_categorical(y_test)\n",
    "np.random.seed(10)\n",
    "net = Network()\n",
    "net.add(FCLayer(28*28, 100))\n",
    "net.add(ActivationLayer(tanh, tanh_prime))\n",
    "net.add(FCLayer(100, 50))\n",
    "net.add(ActivationLayer(tanh, tanh_prime))\n",
    "net.add(FCLayer(50, 10))\n",
    "net.add(ActivationLayer(tanh, tanh_prime))\n",
    "net.use(mse, mse_prime)\n",
    "net.fit(x_train, y_train, epochs=20, learning_rate=0.1)\n",
    "out = net.predict(x_test[0:10])\n",
    "print(\"\\n\")\n",
    "print(\"predicted values : \")\n",
    "print(out, end=\"\\n\")\n",
    "print(\"true values : \")\n",
    "print(y_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
